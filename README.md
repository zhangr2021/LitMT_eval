# [How Good Are LLMs for Literary Translation, Really? Literary Translation Evaluation with Humans and LLMs](https://arxiv.org/abs/2410.18697) 

## Quick Links
- [LitEval-Corpus](#)
    - paragraph-level parallel corpus with verified high-quality human translations of both classic and contemporary published works; 9 MT systems including the GPT-4o, commercial models (DeepL and Google Translate), popular LLMs of various sizes (7-8b Llama 3, TowerInstruct, Qwen, Gemma), and older MT systems (M2M, NLLB).
    This dataset is intended for academic purposes only. Use of this dataset requires agreement to the conditions listed in the [form](https://forms.gle/tGi64MBt59HL4QBQ7). The dataset will be sent via email within two business days. 

- [Code for MT generation and evaluation](codes)

- [Meta information for source and translation](meta): the link indicates version information. The actual content may be acquired elsewhere. 
  
 #### News:
 - 29/Oct/2024: We release student annotation and metric evaluation datasets.
 - 25/02/2025: Codes to reproduce main findings


## LitEval-Corpus:

### Schemes Overview
![Scheme summary](image/scheme_comparison.png)

### Example
![<img align="right" width="400">](image/exmaple_deen.png)
